{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]], shape=(3, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "ftGoals = tf.constant([[2,3], [3,4], [2,2]])\n",
    "\n",
    "ftGoals = tf.cast(ftGoals, dtype=tf.int32)  # (batch, 2)\n",
    "h = (tf.math.greater(ftGoals[..., 0], ftGoals[..., 1]), tf.math.equal(ftGoals[..., 0], ftGoals[..., 1]), tf.math.less(ftGoals[..., 0], ftGoals[..., 1]))\n",
    "h = tf.cast(tf.transpose(h), dtype=tf.float32)  # (batch, nQueries)\n",
    "\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   c1  c2  c3\n",
      "0   1   4   7\n",
      "1   2   5   8\n",
      "2   3   6   9\n",
      "   c1  c2  c3\n",
      "0   1   4   7\n",
      "1   2   5   8\n",
      "2   3   6   9\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "d = { 'c1': [1,2,3], 'c2': [4,5,6], 'c3': [7,8,9]}\n",
    "df = pd.DataFrame(d)\n",
    "print(df)\n",
    "try: df.drop('c4', axis=1)\n",
    "except: pass\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.36614534, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def bell(x, mu, sigma):\n",
    "    x = tf.norm(x)\n",
    "    return tf.math.exp(- tf.math.pow((x-mu)/sigma, 2) / 2) / (sigma * tf.math.sqrt(np.pi*2))\n",
    "\n",
    "print(bell(tf.constant([1.0, 1.0]), 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "config = {}\n",
    "config['baseDate'] = datetime.datetime(2000, 1, 1)\n",
    "print(datetime.datetime.now().year - config['baseDate'].year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "pcode = tf.constant([[1,2,3], [4,5,6], [7,8,9]], dtype=tf.int32)\n",
    "pos = tf.constant([0,2], dtype=tf.int32)\n",
    "\n",
    "print(tf.gather(pcode, pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def find_extrapolation(sequence, tail_data_len):\n",
    "    assert tail_data_len <= len(sequence)\n",
    "    x = np.array([[i] for i in range(tail_data_len)], dtype=np.float32)\n",
    "    y = np.array(sequence[- tail_data_len :], dtype=np.float32)\n",
    "    model = LinearRegression()\n",
    "    model.fit(x, y)\n",
    "    extrapolation = model.predict(np.array([[tail_data_len]], dtype=np.float32))[0]\n",
    "    return extrapolation\n",
    "\n",
    "intervals_a = [1,2,3,4.3]\n",
    "e = find_extrapolation(intervals_a, 3)\n",
    "print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from config import config\n",
    "import data_helpers\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime.now()\n",
    "print(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_helpers.read_large_excel(config['data'], \"contest_total_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_helpers.improve_contest_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gameGraph = data_helpers.createGameGraph(df, renew=True)\n",
    "(a, b) = list(gameGraph.edges())[0]\n",
    "print(gameGraph[a][b]['games'])\n",
    "L = [(ts, id) for (id, ts) in gameGraph[a][b]['games']]\n",
    "print(L)\n",
    "L.sort(reverse=True)\n",
    "print(L)\n",
    "L = [(id, ts) for (ts, id) in L]\n",
    "print(L)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(list(gameGraph.nodes)), len(list(gameGraph.edges)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Although know max conductivity of a single game is 1.0, we start from b_conductance_search of more than 1.0\n",
    "# bacause multiple games between a home and a away might increase conductance between them to more than 1.0.\n",
    "\n",
    "bookie_profit_percent=5.0\n",
    "a_conductance_search=0.01\n",
    "b_conductance_search=15.0\n",
    "conductance365=0.9      # the larger, the fresher it remember the past games\n",
    "conductanceMedTeam=0.8  # the larger, the wider spanning tree. very sensitive for eta.\n",
    "ids_max = 10           #\n",
    "minConductanceStep = 0.000005         \n",
    "renew=True\n",
    "\n",
    "fixture_id_to_ids = data_helpers.fixture_id_to_ids(\n",
    "        df,\n",
    "        gameGraph,\n",
    "        a_conductance_search = a_conductance_search,\n",
    "        b_conductance_search = b_conductance_search,\n",
    "        conductance365 = conductance365, \n",
    "        conductanceMedTeam = conductanceMedTeam,\n",
    "        ids_max = ids_max,\n",
    "        minConductanceStep = minConductanceStep,\n",
    "        renew = renew,\n",
    "        )\n",
    "end = datetime.datetime.now()\n",
    "hours = round((end-start).total_seconds()/60/60, 2)\n",
    "nDataPoints = len(list(fixture_id_to_ids.keys()))\n",
    "maxLen = max([len(ids) for ids in fixture_id_to_ids.values()])\n",
    "filename = data_helpers.dataPrams_to_filename(\n",
    "        bookie_profit_percent,\n",
    "        a_conductance_search, b_conductance_search, conductance365, \n",
    "        conductanceMedTeam, ids_max, minConductanceStep, hours, nDataPoints, maxLen)\n",
    "path = os.path.join('./data', filename + '.json')\n",
    "data_helpers.SaveJsonData(fixture_id_to_ids, path)\n",
    "\n",
    "# filename = 'ids-0.01-15.0-0.9-0.8-130-0.000005-22.28-32601-140'\n",
    "(bookie_profit_percent, a_conductance_search, b_conductance_search, conductance365, \n",
    "        conductanceMedTeam, ids_max, minConductanceStep, hours, nDataPoints, maxLen) \\\n",
    "= data_helpers.filename_to_dataParams(filename)\n",
    "path = os.path.join('./data', filename + '.json')\n",
    "fixture_id_to_ids = data_helpers.LoadJsonData(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = [len(ids) for ids in fixture_id_to_ids.values()]\n",
    "plt.hist(lengths, np.linspace(0, 200, 101))\n",
    "plt.ylim(plt.ylim())\n",
    "maxLen = max(lengths)\n",
    "plt.plot([maxLen, maxLen], plt.ylim())\n",
    "plt.title(f'Max length of ids: {maxLen}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def getPair(df, baseId):\n",
    "    frame = df.loc[df['fixture_id'] == baseId, ['teams_home_team_id', 'teams_away_team_id']]\n",
    "    pairs = list(zip(list(frame['teams_home_team_id']), list(frame['teams_away_team_id'])))\n",
    "    return pairs[0]\n",
    "\n",
    "def showGraph(n):\n",
    "    if(len(list(fixture_id_to_ids.items())) > n):\n",
    "        (baseId, ids) = list(fixture_id_to_ids.items())[n]\n",
    "        print('base pair: ', baseId, getPair(df, int(baseId)), ids)     # No int(.), no work.\n",
    "        \n",
    "        if baseId in ids:\n",
    "            raise(\"BaseId in ids\")\n",
    "\n",
    "        edges = []\n",
    "        for id in ids:\n",
    "            edges.append(getPair(df, id))\n",
    "        print('baseId, nGames, pairs: ', baseId, len(ids), edges)\n",
    "\n",
    "        G = nx.Graph()\n",
    "        G.add_edges_from(edges)\n",
    "\n",
    "        subax1 = plt.subplot(111)\n",
    "        nx.draw(G, with_labels=True)\n",
    "        # print('G.nodes: ', G.nodes)\n",
    "        print('G.edges: ', G.edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 25002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# length = len(list(fixture_id_to_ids.keys()))\n",
    "# for idx in range(length):\n",
    "showGraph(idx)\n",
    "idx += 10\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
